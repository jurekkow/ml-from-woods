{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/3/38/Forest_panorama_2.jpg \"Machine learning from woods - exploring tree-based ensemble models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning from woods - exploring tree-based ensemble models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble models are definitely a hot topic in machine learning area. They win a lot of data science competitions (ex. organized by Kaggle or DrivenData), they are relatively easy to understand (at least some of them) and they usually doesn’t require large clusters of GPU-accelerated machines to give some reasonable results. Therefore ensemble models definitely deserve being in arsenal of anyone who deals with machine learning problems.\n",
    "\n",
    "In this blogpost, I will present some basic theory behind three ensemble models: random forest, AdaBoost and gradient tree boosting. Then, we will see how to implement them using one of the most popular machine learning library: Scikit-Learn and how to improve their out-of-the-box performance. You definitely don’t have to be a machine learning expert or statistical/mathematical genius to understand this text, but it will be easier if you are familiar with some main ideas of supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start by briefly introducing two crucial concepts to understand this section, namely: bias and variance. These two describes dependency between model complexity and data. When bias is high it means that model is too general and ignores many important patterns. On the other hand high variance appears when model “focuses” on gentle details too much, losing broader view on data. Finding optimal model is always a trade-off between bias and variance.\n",
    "\n",
    "In the next sections we will solve classification problems on several datasets. Classification models learn patterns from features that characterize each class, so later given only features of new sample, they can output it’s class label.\n",
    "\n",
    "General idea behind ensemble models is so simple, that [even pigeons could understand it](https://www.theguardian.com/society/2015/nov/19/pigeons-can-identify-cancerous-tissue-on-x-rays-study-finds). Here’s a recipe: get a set of models, aggregate their predictions and you are ready to go! There are of course many tricks to draw best results from ensembles and we’ll discover some of them later, but for now this intuition is sufficient. There is still one evidently unclear thing: why the title is so “woody”, and what does it mean that models are tree-based? It turns out that most commonly used algorithms to combine into ensembles are decision trees. So before diving into how random forest, AdaBoost and gradient tree boosting works, let’s focus on it’s building blocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put it simply, decision trees are models that are build on set of boolean conditions defined on features of data, that are composed in tree form. Using given [criterions](http://scikit-learn.org/stable/modules/tree.html#classification-criteria) they find most optimal decision boundaries. One of their advantage is fact, that they are easy to visualize, so let’s do it to clarify how these boundaries interact with each other.\n",
    "\n",
    "Let’s create simple dataset, where each of 100 samples is defined by only two features (dimensions): X and Y, and there are three classes: “red”, “green” and “blue” using `make_blobs` function from Scikit-Learn library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f566a108828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_STATE = 123  # Ensure repeatability when using randomness\n",
    "COLORS = [\"red\", \"green\", \"blue\"]\n",
    "FEATURES_NAMES = [\"X\", \"Y\"]\n",
    "\n",
    "features, labels = make_blobs(centers=[(-3, 3), (0, -3), (3, 3)], random_state=RANDOM_STATE)\n",
    "labels_colors = [COLORS[label] for label in labels]\n",
    "\n",
    "plt.scatter(features[:, 0], features[:, 1], c=labels_colors)\n",
    "plt.xlabel(FEATURES_NAMES[0])\n",
    "plt.ylabel(FEATURES_NAMES[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create our tree classifier. All Scikit-Learn's share the same API for training: method `fit(features, labels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.tree\n",
    "\n",
    "decision_tree = sklearn.tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will use graphviz library to investigate the structure of out tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"331pt\" height=\"269pt\"\n",
       " viewBox=\"0.00 0.00 331.00 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-265 327,-265 327,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.015686\" stroke=\"#000000\" d=\"M181.5,-261C181.5,-261 73.5,-261 73.5,-261 67.5,-261 61.5,-255 61.5,-249 61.5,-249 61.5,-205 61.5,-205 61.5,-199 67.5,-193 73.5,-193 73.5,-193 181.5,-193 181.5,-193 187.5,-193 193.5,-199 193.5,-205 193.5,-205 193.5,-249 193.5,-249 193.5,-255 187.5,-261 181.5,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">Y &lt;= &#45;0.316</text>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100</text>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [34, 33, 33]</text>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = red</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#39e581\" stroke=\"#000000\" d=\"M105,-149.5C105,-149.5 12,-149.5 12,-149.5 6,-149.5 0,-143.5 0,-137.5 0,-137.5 0,-108.5 0,-108.5 0,-102.5 6,-96.5 12,-96.5 12,-96.5 105,-96.5 105,-96.5 111,-96.5 117,-102.5 117,-108.5 117,-108.5 117,-137.5 117,-137.5 117,-143.5 111,-149.5 105,-149.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 33</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 33, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = green</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M104.9068,-192.9465C97.4527,-181.7113 89.1533,-169.2021 81.6577,-157.9043\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5547,-155.94 76.1097,-149.5422 78.7218,-159.81 84.5547,-155.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"71.1523\" y=\"-170.3457\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.031373\" stroke=\"#000000\" d=\"M248,-157C248,-157 147,-157 147,-157 141,-157 135,-151 135,-145 135,-145 135,-101 135,-101 135,-95 141,-89 147,-89 147,-89 248,-89 248,-89 254,-89 260,-95 260,-101 260,-101 260,-145 260,-145 260,-151 254,-157 248,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"197.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X &lt;= 0.49</text>\n",
       "<text text-anchor=\"middle\" x=\"197.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 67</text>\n",
       "<text text-anchor=\"middle\" x=\"197.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [34, 0, 33]</text>\n",
       "<text text-anchor=\"middle\" x=\"197.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = red</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M150.4206,-192.9465C156.2826,-184.2373 162.6598,-174.7626 168.773,-165.6801\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"171.8476,-167.3802 174.5279,-157.13 166.0405,-163.4716 171.8476,-167.3802\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.3223\" y=\"-177.966\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M176,-53C176,-53 83,-53 83,-53 77,-53 71,-47 71,-41 71,-41 71,-12 71,-12 71,-6 77,0 83,0 83,0 176,0 176,0 182,0 188,-6 188,-12 188,-12 188,-41 188,-41 188,-47 182,-53 176,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"129.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 34</text>\n",
       "<text text-anchor=\"middle\" x=\"129.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [34, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"129.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = red</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M173.5257,-88.9777C167.2667,-80.0954 160.5099,-70.5067 154.2133,-61.5711\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"156.9699,-59.4068 148.3487,-53.2485 151.2479,-63.4389 156.9699,-59.4068\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#8139e5\" stroke=\"#000000\" d=\"M311,-53C311,-53 218,-53 218,-53 212,-53 206,-47 206,-41 206,-41 206,-12 206,-12 206,-6 212,0 218,0 218,0 311,0 311,0 317,0 323,-6 323,-12 323,-12 323,-41 323,-41 323,-47 317,-53 311,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"264.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 33</text>\n",
       "<text text-anchor=\"middle\" x=\"264.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 33]</text>\n",
       "<text text-anchor=\"middle\" x=\"264.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = blue</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M221.1217,-88.9777C227.2887,-80.0954 233.9461,-70.5067 240.1501,-61.5711\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"243.1003,-63.4589 245.9285,-53.2485 237.3503,-59.4666 243.1003,-63.4589\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f565f9a7a58>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "tree_data = sklearn.tree.export_graphviz(decision_tree,\n",
    "                                         out_file=None,\n",
    "                                         feature_names=FEATURES_NAMES,\n",
    "                                         class_names=COLORS,\n",
    "                                         rounded=True,\n",
    "                                         filled=True,\n",
    "                                         impurity=False)\n",
    "tree_graph = graphviz.Source(tree_data)\n",
    "tree_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First row in node describes decision boundary (not present in leafs), next is number of samples that falls into that node, another one is node’s samples distribution between classes, and the last one is most common class in the node, which in leafs is interpreted as tree output label.\n",
    "\n",
    "As you can see, decision trees handled well this toy example, and in fact they handle well many real-life problems. Moreover they need very little data preprocessing: ex. scaling data is not needed, because trees will find decision boundaries independently of magnitude of given feature. In addition, decision trees can handle both numerical and categorical data. However they are very prone to overfitting - what means they easily become high-variance models. That results in instability, because small changes in training set can result in major decision boundaries shifts. There are many ways to handle this problem and the most successful one is using more than one tree to build ensemble classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may ask yourself, how using many high-variance models can in fact reduce variance and decrease general error? Let’s imagine you have several datasets, each representing the same phenomenon, but they are taken from different samples of population. If you train decision tree on one of this sets, you won’t have amazing overall performance, but if you will ask set of trees trained on different data to come to a consensus, individual variances will cancel out. But how to train decision trees, so that we have several different models using just one training dataset? That’s where idea of bagging is coming with rescue. Let’s say you have 1000 samples in your training set, and you want to create 25 new training sets to train 25 different decision trees. You just pick randomly 1000 samples (with replacement) from your training set (bag). In new training set, some samples from original one will appear more than once, and some won’t appear at all. If you repeat this procedure 25 times, you’ll have 25 different training sets for building your trees. To get final prediction of ensemble, you just pick the most common output of all trees. You may also use probabilities of classes instead of just labels. They can be taken from distribution of class representants in final tree node (leaf). Using this attitude, your model will favour more confident trees, which sounds reasonable.\n",
    "\n",
    "But random forest is more than just bagging trees. To make individual trees even more diverse, you randomly limit set of features available when splitting a node. This way, each time when tree tries to find an optimal decision boundary, it “sees” only random subset of all features. This draw take place each time node is split. Common measure is to randomly take $\\sqrt{n}$ or $\\log_{2}{n}$ features to make a split wheren is original number of features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another family of ensembling methods called boosting, that tackles problem from the other side. This time we will use many weak learners (only slightly better than random guessing), that are high-bias models. Because every base model will be biased in different way, they will cancel out general bias.\n",
    "\n",
    "Trees that build AdaBoost ensemble, are created sequentially in such a way that new tree should reduce error made by previous models. What is important, once tree is trained, it remains untouched during rest of ensemble training. Trees used in AdaBoost are really shallow, often having only 2 leafs (such trees are called decision stumps). Using trees as base learners is not required by AdaBoost algorithm, but it’s most common practice.\n",
    "\n",
    "When creating AdaBoost model, all training samples has weights bounded to it. Initially all weights are the same and equal 1N, where N is number of samples. After one tree is trained, weights of wrongly classified samples are increased, and that modified version of dataset is an input to another tree from ensemble. This procedure continues until maximum number of trees is reached or adding new tree don’t result in reducing training error. Output prediction is combination of outputs from all shallow trees, weighted by each tree accuracy. If you are curious what formulas are used for weighting samples, as well as predictions, I highly recommend [blogpost from Jason Brownlee about AdaBoost](https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient tree boosting is next member of boosting algorithms family. Similarly to AdaBoost, it is built from set of small trees, but usually slightly deeper than decision stumps. Trees are trained sequentially, just like in AdaBoost, but training of individual trees is not the same.\n",
    "\n",
    "Trees that are used in gradient tree boosting differ from trees that was described earlier. They are regression trees, so theirs aim is to produce some real value number for each sample. In fact, they are pretty similar to classification decision trees, but they put into leafs samples that have similar (ideally, the same) real values bounded to them. Output value from given leaf is mean value from all samples that get there during training. In case of gradient tree boosting, such trees are constructed for each class independently. They learn to output probability that given sample is a member of given class. Values bounded to samples are either 0 (member of another class) or 1 (member of this class), so perfect tree will output only 0 or 1 and flawed one will produce numbers between 0 and 1.\n",
    "\n",
    "The main idea behind the algorithm is to iteratively find new trees that minimizes loss function: measure to tell how bad model is. It have to be differentiable, and it’s picked based on problem to solve. For classification it is usually log loss, that is just negative mean of log-probabilities that sample xi is classified as it’s label:\n",
    "$$loss = -\\frac{1}{N}\\sum_{i=1}^{N}{\\log{p(TRUE LABEL | x_i)}}$$\n",
    "Having loss value, we can calculate so-called pseudo residuals, that are gradients (partial derivatives) of loss with respect to predictions from previous trees. Pseudo residuals are then plugged instead of labels (ones and zeros in fact) when training a new tree. It does make sense, because new tree will treat differently samples that were completely wrong classified by previous trees and the ones that were pretty close to correct prediction. In addition, trees are parameterized, and these parameters are also optimized during training in order to reduce loss. If you are hungry for more math that explains the whole process you may want to read [wikipedia article](https://en.wikipedia.org/wiki/Gradient_boosting#Algorithm), or [whitepaper](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf) from one of the fathers of this method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our algorithms, we will use plain old dataset of Australian Credit Approval. Based on given features of customer (feature names was removed, but it's not important for us), our model will try to predict whether to accept or reject credit card application. There are only two classes: accepted and rejected, so this problem can be named as binary classification. This dataset is available [here](http://mldata.org/repository/data/viewslug/australian/), and we will use an utility Scikit-Learn's function `fetch_mldata` to easily download datasets from mldata.org. We also shuffle data and split it to train and test sets, so after training we can evaluate our model on previously unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "DATASET_NAME = \"australian\"\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "data_bunch = fetch_mldata(DATASET_NAME)\n",
    "features, labels = shuffle(data_bunch.data, data_bunch.target, random_state=RANDOM_STATE)\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble models in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
